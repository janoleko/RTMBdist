---
title: "Examples"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Examples}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, message = FALSE}
library(RTMBdist)
```

# Example 1: Chicken weight

Our first example is the chicken weight data set, already used in the `RTMB` Introduction vignette.

We fit the same random regression model, where each chick has its own intercept and slope parameters that are assumed to be normally distributed. However, instead of assuming normal errors, we assume that the observations given the time and chick follow a Box-Cox Cole-Green (BCCG) distribution, which allows for skewness in the data.

```{r data}
data(ChickWeight)
```

```{r parameters}
parameters <- list(
  mua=0,          ## Mean slope
  log_sda=1,      ## log-Std of slopes
  mub=0,          ## Mean intercept
  log_sdb=1,      ## log-Std of intercepts
  log_sigma=0,    ## log-Scale of BCCG distribution
  nu = 0.1,       ## Skewness of BCCG distribution
  a=rep(0, 50),   ## Random slope by chick
  b=rep(5, 50)    ## Random intercept by chick
)
```

The joint negative log-likelihood function has the same structure as in the `RTMB` vignette, but with the normal likelihood replaced by the BCCG likelihood, and hence also some necessary parameter transformations.

```{r likelihood}
nll <- function(parms) {
  getAll(ChickWeight, parms, warn=FALSE)
  ## Optional (enables extra RTMB features)
  weight <- OBS(weight)
  ## Initialize joint negative log likelihood
  nll <- 0
  ## Random slopes
  sda <- exp(log_sda); ADREPORT(sda)
  nll <- nll - sum(dnorm(a, mean=mua, sd=sda, log=TRUE))
  ## Random intercepts
  sdb <- exp(log_sdb); ADREPORT(sdb)
  nll <- nll - sum(dnorm(b, mean=mub, sd=sdb, log=TRUE))
  ## Data
  predWeight <- exp(a[Chick] * Time + b[Chick])
  sigma <- exp(log_sigma); ADREPORT(sigma)
  nll <- nll - sum(dbccg(weight, mu=predWeight, sigma=sigma, nu=nu, log=TRUE))
  ## Get predicted weight uncertainties
  ADREPORT(predWeight)
  ## Return
  nll
}
```

The model can then again be fitted by constructing the Laplace-approximated marginal log-likelihood function and optimising this using any standard numerical optimiser.

```{r model fitting}
obj <- MakeADFun(nll, parameters, random=c("a", "b"), silent = TRUE)
opt <- nlminb(obj$par, obj$fn, obj$gr)
```

We can use `RTMB`'s automatic simulation capabilities to simulate from the fitted model and run a check whether the Laplace approximation is adequate. All of this is done by a simple call to `checkConsistency()`.

```{r laplace_check}
set.seed(1)
chk <- checkConsistency(obj)
chk
```
Lastly, we can also automatically calculate quantile residuals via probability integral transform using `oneStepPredict()`.

```{r residuals}
osa <- oneStepPredict(obj, discrete=FALSE, trace=FALSE)
qqnorm(osa$res); abline(0,1)
```

We see that this model is still not suitable but a bit better than the Gaussian model in the `RTMB` vignette.


# Example 2: Distributional regression with penalised splines

Our second example will cover the famous dutch boys BMI data set, which is part of the `gamlss.data` package. We will fit a distributional regression model where the location, scale, and skewness parameters of the Box-Cox power exponential (BCPE) distribution are modelled as smooth functions of age using penalised splines. The kurtosis parameter will be kept constant.

```{r cleanup, include=FALSE}
TMB::FreeADFun(obj)
```

We start by loading packages that are needed.

```{r packages, message = FALSE}
library(gamlss.data)   # contains dutch-boys data
library(LaMa)          # for creating model matrices
library(Matrix)        # to create sparse matrices
```

```{r data_boys}
data(dbbmi)
```

We will use the function `make_matrices()` from package `LaMa` to conveniently create design and penalty matrices for the smooth functions. The penalty matrix is converted to a sparse matrix using the `Matrix` package, to work with `RTMB`'s `dgmrf()` function.

```{r creating model matrices}
k <- 10 # basis dimension
modmat <- make_matrices(~ s(age, bs="cs", k=k), data = dbbmi) 
X <- modmat$Z                              # design matrix
S <- Matrix(modmat$S[[1]], sparse = TRUE)  # sparse penalty matrix
```

The joint negative log-likelihood function computes covariate dependent location, scale, and skewness parameters using the design matrix and regression coefficients. The regression coefficients are treated as random effects with a multivariate normal distribution with zero mean and a precision matrix that is a scaled version of the penalty matrix, which is achieved by calling `dgmrf()` for each of them. The scaling parameters (smoothing parameters) are estimated by restricted maximum likelihood (REML), which is achieved by treating them as fixed effects and integrating out the regression coefficients and other fixed effects using the Laplace approximation.

```{r likelihood2}
nll2 <- function(par) {
  "c" <- ADoverload("c")
  getAll(par, dat, warn=FALSE)
  ## Optional (enables extra RTMB features)
  bmi <- OBS(bmi)
  ## Calculating parameters
  beta_mu <- c(beta0_mu, beta_age_mu)
  beta_sigma <- c(beta0_sigma, beta_age_sigma)
  beta_nu <- c(beta0_nu, beta_age_nu)
  mu <- exp(X %*% beta_mu); ADREPORT(mu) # location
  sigma <- exp(X %*% beta_sigma); ADREPORT(sigma) # scale
  nu <- X %*% beta_nu; ADREPORT(nu) # skewness
  tau <- exp(log_tau); ADREPORT(tau) # kurtosis
  ## Likelihood: Box-Cox power exponential distribution
  nll <- - sum(dbcpe(bmi, mu, sigma, nu, tau, log=TRUE))
  ## Penalised splines as random effects
  lambda <- exp(log_lambda); REPORT(lambda)
  nll <- nll - dgmrf(beta_age_mu, 0, lambda[1] * S, log=TRUE)
  nll <- nll - dgmrf(beta_age_sigma, 0, lambda[2] * S, log=TRUE)
  nll <- nll - dgmrf(beta_age_nu, 0, lambda[3] * S, log=TRUE)
  nll
}
```

```{r parameters and data}
par <- list(
  beta0_mu = log(18),
  beta0_sigma = log(0.15),
  beta0_nu = -1,
  beta_age_mu = rep(0, k-1),
  beta_age_sigma = rep(0, k-1),
  beta_age_nu = rep(0, k-1),
  log_tau = log(2),
  log_lambda = log(rep(1e4, 3))
)
dat <- list(
  bmi = dbbmi$bmi,
  age = dbbmi$age,
  X = X,
  S = S
)
```

As we are using REML, we are integrating out all parameters other than the smoothing parameters `log_lambda`, which are treated as fixed effects. The model is then fitted by constructing the Laplace-approximated marginal log-likelihood function and optimising this using any standard numerical optimiser.

```{r REML fit}
# Restricted maximum likelihood (REML) - also integrating out fixed effects
random <- names(par)[names(par) != "log_lambda"]
obj2 <- MakeADFun(nll2, par, random = random, silent = TRUE)
opt2 <- nlminb(obj2$par, obj2$fn, obj2$gr)
```

We can have access to all `ADREPORT()`ed quantities and their standard deviation using `sdreport()`.

```{r results}
sdr <- sdreport(obj2, ignore.parm.uncertainty = TRUE)
par <- as.list(sdr, "Est", report = TRUE)
par_sd <- as.list(sdr, "Std", report = TRUE)
```

This way, we can easily plot the estimated smooth functions with confidence intervals and the conditional distribution of BMI given age.

```{r effects_plot}
age <- dbbmi$age
ord <- order(age)

## Plotting estimated effects
par(mfrow = c(1,3))
plot(age[ord], par$mu[ord], type = "l", lwd = 2, bty = "n", xlab = "Age", ylab = "Mu")
polygon(c(age[ord], rev(age[ord])),
        c(par$mu[ord] + 2*par_sd$mu[ord], rev(par$mu[ord] - 2*par_sd$mu[ord])),
        col = "#00000020", border = "NA")
plot(age[ord], par$sigma[ord], type = "l", lwd = 2, bty = "n", xlab = "Age", ylab = "Sigma")
polygon(c(age[ord], rev(age[ord])),
        c(par$sigma[ord] + 2*par_sd$sigma[ord], rev(par$sigma[ord] - 2*par_sd$sigma[ord])),
        col = "#00000020", border = "NA")
plot(age[ord], par$nu[ord], type = "l", lwd = 2, bty = "n", xlab = "Age", ylab = "Nu")
polygon(c(age[ord], rev(age[ord])),
        c(par$nu[ord] + 2*par_sd$nu[ord], rev(par$nu[ord] - 2*par_sd$nu[ord])),
        col = "#00000020", border = "NA")
```

```{r cond_dist}
## Plotting conditional distribution
par(mfrow = c(1,1))
plot(dbbmi$age, dbbmi$bmi, pch = 16, col = "#00000020",
     xlab = "Age", ylab = "BMI", bty = "n")
lines(age[ord], par$mu[ord], lwd = 3, col = "deepskyblue")

# compute quantiles (point estimates)
par <- lapply(par, as.numeric)
ps <- seq(0, 1, length = 8)
ps[1] <- 0.005 # avoid 0 and 1
ps[length(ps)] <- 0.995 # avoid 0 and 1
for(p in ps) {
  q <- qbcpe(p, par$mu, par$sigma, par$nu, par$tau)
  lines(age[ord], q[ord], col = "deepskyblue")
}

legend("topleft", lwd = c(3, 1), col = "deepskyblue", legend = c("Mean", "Quantiles"), bty = "n")
```
